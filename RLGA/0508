5月8日晚上：
完成RLGA的实现
1.先将DNA空间分成6部分
2.每一部分都从环境中挑选出一个Q值最大的（选择的应该是pop，因为环境是相同的），作为该agent的action，通过分割的方法找到对应的dna值，并行发生6个action得到6个参数值
3.将这6个参数值传入get_fitness，得到的值与之前找到的（这次就不能初始化为0了），做一次减法，得到的差值作为联合reward，来以此更新六个agent的q表值
4，比较fitness的值与当前最大值，更新最大值和对应参数
